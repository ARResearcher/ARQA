{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the size value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(\"_piece_virtual_mask.png\"):\n",
    "        meta_filename = filename[:-23]\n",
    "        print(meta_filename)\n",
    "\n",
    "        ar_region_mask = cv2.imread(dataset_path+\"/\"+meta_filename+\"_piece_virtual_mask.png\", cv2.IMREAD_GRAYSCALE) \n",
    "        ar_region_mask = (ar_region_mask > 128).astype(np.uint8)\n",
    "\n",
    "        ar_depth_raw = np.load(dataset_path+\"/\"+meta_filename+\"_ar_depth.npy\")\n",
    "        #ar_depth_raw = np.load(dataset_path+\"/size_depth_array_\"+meta_filename+\"_ar.npy\")\n",
    "        mask_virtual_depth = ar_depth_raw[ar_region_mask > 0]\n",
    "        size = np.max(mask_virtual_depth)-np.min(mask_virtual_depth)\n",
    "        print(meta_filename, \"size: \", str(size))\n",
    "        print(type(df[\"filename\"].tolist()[0]))\n",
    "\n",
    "        # Update the size column where the filename matches\n",
    "        csv_mask = df[\"filename\"] == meta_filename\n",
    "        if csv_mask.any():\n",
    "            df.loc[csv_mask, \"size\"] = size  # Update the 'size' column\n",
    "            df.to_csv(csv_file, index=False)  # Save back to CSV\n",
    "            print(f\"Updated size for {meta_filename} -> {size}\")\n",
    "        else:\n",
    "            print(f\"Filename {meta_filename} not found in CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the clipping value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_white_areas(binary_image):\n",
    "    # Compute connected components. \n",
    "    # Note: The function returns the total number of labels, where label 0 is the background.\n",
    "    num_labels, labels = cv2.connectedComponents(binary_image)\n",
    "    # Number of closed white regions is total labels minus one (background)\n",
    "    return num_labels - 1\n",
    "\n",
    "def get_mean_depth_per_region(binary_mask, depth_array, t=0.01):\n",
    "    \"\"\"\n",
    "    Computes the mean depth value of each white area in the binary mask.\n",
    "\n",
    "    Parameters:\n",
    "        binary_mask (numpy.ndarray): A binary mask where white areas (255) represent regions of interest.\n",
    "        depth_array (numpy.ndarray): A depth map of the same shape as the binary mask.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (label, mean_depth_value).\n",
    "    \"\"\"\n",
    "    # Label connected components\n",
    "    num_labels, labels = cv2.connectedComponents(binary_mask)\n",
    "\n",
    "    mean_depth_values = []\n",
    "    new_mask = np.zeros_like(binary_mask)\n",
    "\n",
    "    for label in range(1, num_labels):  # Skip background (label 0)\n",
    "        region_mask = labels == label  # Boolean mask for this region\n",
    "        mean_depth = depth_array[region_mask].mean()  # Compute mean depth\n",
    "        #print(mean_depth)\n",
    "        mean_depth_values.append((label, mean_depth))\n",
    "        if mean_depth > t:\n",
    "            new_mask[region_mask] = 1  # Keep this region\n",
    "\n",
    "    return mean_depth_values, new_mask\n",
    "\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(\"_full_virtual_mask.png\"):\n",
    "        meta_filename = filename[:-22]\n",
    "        print(meta_filename)\n",
    "\n",
    "        if \"hl_\" in meta_filename:\n",
    "            ar_img = cv2.imread(dataset_path+\"/\"+meta_filename+\"_ar.jpg\")\n",
    "        else:\n",
    "            ar_img = cv2.imread(dataset_path+\"/\"+meta_filename+\"_ar.png\")\n",
    "        ar_img = cv2.cvtColor(ar_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        ar_region_mask = cv2.imread(dataset_path+\"/\"+meta_filename+\"_piece_virtual_mask.png\", cv2.IMREAD_GRAYSCALE) \n",
    "        ar_region_mask = (ar_region_mask > 128).astype(np.uint8)\n",
    "\n",
    "\n",
    "        raw_depth = np.load(dataset_path+\"/\"+meta_filename+\"_raw_depth.npy\")\n",
    "        #raw_depth = np.load(dataset_path+\"/size_depth_array_\"+meta_filename+\"_raw.npy\")\n",
    "        raw_depth = (raw_depth - raw_depth.min()) / (raw_depth.max() - raw_depth.min())\n",
    "        ar_depth = np.load(dataset_path+\"/\"+meta_filename+\"_ar_depth.npy\")\n",
    "        #ar_depth = np.load(dataset_path+\"/size_depth_array_\"+meta_filename+\"_ar.npy\")\n",
    "        ar_depth = (ar_depth - ar_depth.min()) / (ar_depth.max() - ar_depth.min())\n",
    "\n",
    "        diff_depth = abs(raw_depth - ar_depth)\n",
    "        mean_depth_values, new_mask = get_mean_depth_per_region(ar_region_mask, diff_depth, t=0.08)\n",
    "        \n",
    "        new_count = count_white_areas(new_mask)\n",
    "        if new_count==0:\n",
    "            new_count = count_white_areas(ar_region_mask)\n",
    "\n",
    "        csv_mask = df[\"filename\"] == meta_filename\n",
    "        if csv_mask.any():\n",
    "            df.loc[csv_mask, \"clipping\"] = new_count  # Update the 'size' column\n",
    "            df.to_csv(csv_file, index=False)  # Save back to CSV\n",
    "            print(f\"Updated new_count for {meta_filename} -> {new_count}\")\n",
    "        else:\n",
    "            print(f\"Filename {meta_filename} not found in CSV.\")\n",
    "        '''\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.imshow(ar_img)\n",
    "        print(mean_depth_values)\n",
    "        plt.title('Original ar image')\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.imshow(ar_region_mask)\n",
    "        plt.title('mask image have '+str(count_white_areas(ar_region_mask)) + \" masks\")\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.imshow(ar_depth)\n",
    "        plt.title('AR Depth Map')\n",
    "        plt.colorbar()\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.imshow(new_mask)\n",
    "        plt.title('new mask image have '+str(count_white_areas(new_mask)) + \" masks\")\n",
    "        plt.colorbar()\n",
    "        '''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the floating value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obvious_region(binary_mask, depth_array, t=0.01):\n",
    "    \"\"\"\n",
    "    Computes the mean depth value of each white area in the binary mask.\n",
    "\n",
    "    Parameters:\n",
    "        binary_mask (numpy.ndarray): A binary mask where white areas (255) represent regions of interest.\n",
    "        depth_array (numpy.ndarray): A depth map of the same shape as the binary mask.\n",
    "\n",
    "    Returns:\n",
    "        list of tuples: Each tuple contains (label, mean_depth_value).\n",
    "    \"\"\"\n",
    "    # Label connected components\n",
    "    num_labels, labels = cv2.connectedComponents(binary_mask)\n",
    "\n",
    "    new_mask = np.zeros_like(binary_mask)\n",
    "\n",
    "    for label in range(1, num_labels):  # Skip background (label 0)\n",
    "        region_mask = labels == label  # Boolean mask for this region\n",
    "        mean_depth = depth_array[region_mask].mean()  # Compute mean depth\n",
    "        if mean_depth > t:\n",
    "            new_mask[region_mask] = 1  # Keep this region\n",
    "\n",
    "    return new_mask\n",
    "\n",
    "def is_object_floating(ar_img, depth_array, binary_mask, bottom_margin=10, below_margin=10, threshold=10, min_contact_ratio=0.1):\n",
    "    \"\"\"\n",
    "    Determines whether an object is floating, accounting for partial support.\n",
    "\n",
    "    Parameters:\n",
    "        depth_array (numpy array): The depth data in (w, h) format.\n",
    "        binary_mask (numpy array): The binary mask of the object.\n",
    "        bottom_margin (int): Pixels from the bottom to consider for contact detection.\n",
    "        threshold (float): Depth difference threshold to classify as floating.\n",
    "        min_contact_ratio (float): Minimum fraction of the bottom in contact to consider the object as \"resting\".\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the object is floating, False otherwise.\n",
    "    \"\"\"\n",
    "    object_indices = np.argwhere(binary_mask > 0)\n",
    "    if len(object_indices) == 0:\n",
    "        return -1, -1, -1  # No object found\n",
    "\n",
    "    # Find bottom-most row of the object\n",
    "    max_y = np.max(object_indices[:, 0])\n",
    "\n",
    "    # Select the bottom part of the object (a few pixels above max_y)\n",
    "    bottom_mask = np.zeros_like(binary_mask)\n",
    "    bottom_region = (object_indices[:, 0] >= max_y - bottom_margin)\n",
    "    bottom_indices = object_indices[bottom_region]\n",
    "    bottom_mask[bottom_indices[:, 0], bottom_indices[:, 1]] = 1\n",
    "    # Extract depth of the bottom region of the object\n",
    "    bottom_depths = depth_array[bottom_mask > 0]\n",
    "\n",
    "    # Get background depth just below the object\n",
    "    background_mask = np.zeros_like(binary_mask)\n",
    "    # Check pixels from 1 to `below_margin` pixels below the object\n",
    "    for shift in range(1, below_margin + 1):\n",
    "        below_indices = bottom_indices + np.array([shift, 0])  # Shift downward\n",
    "        valid_below_indices = below_indices[:, 0] < depth_array.shape[0]  # Ensure within bounds\n",
    "        below_indices = below_indices[valid_below_indices]\n",
    "        background_mask[below_indices[:, 0], below_indices[:, 1]] = 1\n",
    "    background_mask[object_indices[:, 0], object_indices[:, 1]] = 0\n",
    "    # Extract depth of the bottom background region of the object\n",
    "    background_depths = depth_array[background_mask > 0]\n",
    "\n",
    "    # Compute median depth values\n",
    "    if len(bottom_depths) == 0 or len(background_depths) == 0:\n",
    "        print(\"Not enough data\", len(bottom_depths), len(background_depths))\n",
    "        return -1, -1, -1  # Not enough data\n",
    "\n",
    "    object_bottom_median = np.mean(bottom_depths)\n",
    "    background_median = np.mean(background_depths)\n",
    "\n",
    "    # Detect floating based on depth difference\n",
    "    floating_condition = object_bottom_median - background_median > threshold\n",
    "\n",
    "    contact_mask = (bottom_mask > 0) & (abs(depth_array-background_median) <= threshold)  # Small depth difference = contact\n",
    "\n",
    "    # Label connected contact regions\n",
    "    labeled_contact, num_labels = label(contact_mask)\n",
    "\n",
    "    # Find the largest contact region\n",
    "    largest_contact_area = max(np.bincount(labeled_contact.flat)[1:], default=0)  # Ignore background label (0)\n",
    "\n",
    "    # Compute ratio of contact points to total bottom pixels\n",
    "    total_bottom_pixels = np.count_nonzero(bottom_mask)\n",
    "    contact_ratio = largest_contact_area / total_bottom_pixels if total_bottom_pixels > 0 else 0\n",
    "\n",
    "    # Final decision: if most of the bottom is unsupported, it's floating\n",
    "    is_floating = floating_condition or (contact_ratio < min_contact_ratio)\n",
    "\n",
    "    original_img = ar_img\n",
    "    original_img[:,:,0] = depth_array * 255.0\n",
    "    original_img[:,:,1] = depth_array * 255.0\n",
    "    original_img[:,:,2] = depth_array * 255.0\n",
    "    original_img = original_img.astype(float) / 255.0  # Normalize to 0-1 range\n",
    "\n",
    "    # Create colored overlay masks\n",
    "    overlay = np.zeros_like(original_img)\n",
    "\n",
    "    # Define colors (in RGB)\n",
    "    bottom_color = np.array([1, 0, 0])  # Red for bottom region\n",
    "    background_color = np.array([0, 1, 0])  # Green for background region\n",
    "    contact_color = np.array([0, 0, 1])  # Blue for contact region\n",
    "\n",
    "    # Apply color to mask regions\n",
    "    for i in range(3):  # Apply to each RGB channel\n",
    "        overlay[:, :, i] += bottom_mask * bottom_color[i]  # Red overlay\n",
    "        overlay[:, :, i] += background_mask * background_color[i]  # Green overlay\n",
    "        overlay[:, :, i] += contact_mask * contact_color[i]  # Blue overlay\n",
    "\n",
    "    # Blend overlay with original image\n",
    "    alpha = 0.5\n",
    "    blended_img = (1 - alpha) * original_img + alpha * overlay\n",
    "\n",
    "    # Ensure values are in valid range\n",
    "    blended_img = np.clip(blended_img, 0, 1)  # Keep values between 0 and 1\n",
    "    blended_img = (blended_img * 255).astype(np.uint8)  # Convert back to 0-255 range\n",
    "    # Show the result\n",
    "    '''\n",
    "    plt.figure(figsize=(16, 12))\n",
    "    plt.imshow(blended_img)\n",
    "    plt.title(\"Bottom Mask (Red) & Background Mask (Green) Over Original Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    '''\n",
    "    return object_bottom_median - background_median, contact_ratio, is_floating\n",
    "\n",
    "for filename in os.listdir(dataset_path):\n",
    "    if filename.endswith(\"_full_virtual_mask.png\"):\n",
    "        meta_filename = filename[:-22]\n",
    "        print(meta_filename)\n",
    "\n",
    "        if \"hl_\" in meta_filename:\n",
    "            ar_img = cv2.imread(dataset_path+\"/\"+meta_filename+\"_ar.jpg\")\n",
    "        else:\n",
    "            ar_img = cv2.imread(dataset_path+\"/\"+meta_filename+\"_ar.png\")\n",
    "        \n",
    "        ar_img = cv2.cvtColor(ar_img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "        ar_region_mask = cv2.imread(dataset_path+\"/\"+meta_filename+\"_full_virtual_mask.png\", cv2.IMREAD_GRAYSCALE) \n",
    "        ar_region_mask = (ar_region_mask > 128).astype(np.uint8)\n",
    "\n",
    "        raw_depth = np.load(dataset_path+\"/\"+meta_filename+\"_raw_depth.npy\")\n",
    "        #raw_depth = np.load(dataset_path+\"/depth_array_\"+meta_filename+\"_raw.npy\")\n",
    "        raw_depth = (raw_depth - raw_depth.min()) / (raw_depth.max() - raw_depth.min())\n",
    "        ar_depth_origin = np.load(dataset_path+\"/\"+meta_filename+\"_ar_depth.npy\")\n",
    "        #ar_depth_origin = np.load(dataset_path+\"/depth_array_\"+meta_filename+\"_ar.npy\")\n",
    "        ar_depth = (ar_depth_origin - ar_depth_origin.min()) / (ar_depth_origin.max() - ar_depth_origin.min())\n",
    "\n",
    "        diff_depth = abs(raw_depth - ar_depth)\n",
    "        new_mask = get_obvious_region(ar_region_mask, diff_depth, t=0.08)\n",
    "        \n",
    "        diff, contact_ratio, floating = is_object_floating(ar_img, ar_depth_origin, new_mask, bottom_margin=40, below_margin=30, threshold=0.1, min_contact_ratio=0.2)\n",
    "        print(\"Is the object floating?\", diff, contact_ratio, floating) \n",
    "\n",
    "        csv_mask = df[\"filename\"] == meta_filename\n",
    "        if csv_mask.any():\n",
    "            df.loc[csv_mask, \"floating_depth_diff\"] = diff  \n",
    "            df.loc[csv_mask, \"floating_contact_ratio\"] = contact_ratio\n",
    "            df.to_csv(csv_file, index=False)  # Save back to CSV\n",
    "            print(f\"Updated floating for {meta_filename} -> {diff}, {contact_ratio}\")\n",
    "        else:\n",
    "            print(f\"Filename {meta_filename} not found in CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the brightness value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_average_luminosity_numpy(image_path):\n",
    "    \"\"\"\n",
    "    Computes the average luminosity (brightness) of an image using the weighted method:\n",
    "       Luminosity = 0.299*R + 0.587*G + 0.114*B\n",
    "    Returns a float value representing the average luminosity (0-255 for 8-bit).\n",
    "    \"\"\"\n",
    "    # Read image into NumPy array (H x W x 3)\n",
    "    img = np.array(Image.open(image_path).convert(\"RGB\"), dtype=float)\n",
    "    \n",
    "    # Separate channels\n",
    "    R = img[..., 0]\n",
    "    G = img[..., 1]\n",
    "    B = img[..., 2]\n",
    "    \n",
    "    # Compute luminosity per pixel\n",
    "    luminosity = 0.299 * R + 0.587 * G + 0.114 * B\n",
    "    \n",
    "    # Return the average\n",
    "    return np.mean(luminosity)\n",
    "\n",
    "def order_images_by_luminosity(directory_path):\n",
    "    \"\"\"\n",
    "    1. Find files in `directory_path`\n",
    "    2. Compute their average luminosity\n",
    "    \"\"\"\n",
    "\n",
    "    meta_filenames_dic = {}\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if \"cropped\" in filename and \"background\" not in filename:\n",
    "        #if \".png\" in filename and \"_\" in filename:\n",
    "            meta_filename = filename.split(\"_cropped_\")[0]  # Extract only the first part\n",
    "            #meta_filename = filename.split(\"_\")[0]\n",
    "            if meta_filename not in meta_filenames_dic.keys():\n",
    "                meta_filenames_dic[meta_filename] = {\"real_luminosities\":[], \"virtual_luminosity\": -1}\n",
    "            file_path = os.path.join(directory_path, filename)\n",
    "            # 2. Compute luminosity\n",
    "            try:\n",
    "                lum = compute_average_luminosity_numpy(file_path)\n",
    "                if \"virtual\" in filename:\n",
    "                    meta_filenames_dic[meta_filename][\"virtual_luminosity\"] = lum\n",
    "                else:\n",
    "                    meta_filenames_dic[meta_filename][\"real_luminosities\"].append(lum)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not process '{filename}': {e}\")\n",
    "    \n",
    "    for meta_filename in meta_filenames_dic.keys():\n",
    "        csv_mask = df[\"filename\"] == meta_filename\n",
    "        print(meta_filename)\n",
    "        if csv_mask.any():\n",
    "            if len(meta_filenames_dic[meta_filename][\"real_luminosities\"]) == 0:\n",
    "                brightness_min = meta_filenames_dic[meta_filename][\"virtual_luminosity\"]\n",
    "                brightness_max = meta_filenames_dic[meta_filename][\"virtual_luminosity\"]\n",
    "            else:\n",
    "                brightness_min = np.min(meta_filenames_dic[meta_filename][\"real_luminosities\"])\n",
    "                brightness_max = np.max(meta_filenames_dic[meta_filename][\"real_luminosities\"])\n",
    "            brightness_virtual = meta_filenames_dic[meta_filename][\"virtual_luminosity\"]\n",
    "            df.loc[csv_mask, \"brightness_min\"] = brightness_min\n",
    "            df.loc[csv_mask, \"brightness_max\"] = brightness_max\n",
    "            df.loc[csv_mask, \"brightness_virtual\"] = brightness_virtual\n",
    "            df.to_csv(csv_file, index=False)  # Save back to CSV\n",
    "            print(f\"Updated brightness for {meta_filename} -> {brightness_min}, {brightness_max}, {brightness_virtual}\")\n",
    "        else:\n",
    "            print(f\"Filename {meta_filename} not found in CSV.\")\n",
    "\n",
    "order_images_by_luminosity(dataset_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the light direction value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of Excel files to combine\n",
    "xlsx_files = ['ARQA_lightdir.xlsx', 'ARpatches_lightdir.xlsx', 'cropped_real_lightdir.xlsx']\n",
    "\n",
    "# Read and combine all Excel files\n",
    "combined_df = pd.concat([pd.read_excel(file) for file in xlsx_files], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "combined_df.to_csv('light_direction_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_csv_file = \"light_direction_results.csv\"\n",
    "light_df = pd.read_csv(light_csv_file, dtype={\"filename\": str})\n",
    "\n",
    "for meta_filename in meta_filenames:\n",
    "    light_direction_real_list = light_df.loc[light_df[\"filename\"].str.contains(meta_filename+\"_cropped\", na=False) \n",
    "                                             & ~light_df[\"filename\"].str.contains(\"virtual\", na=False) \n",
    "                                             & ~light_df[\"filename\"].str.contains(\"background\", na=False), \"results\"].tolist()\n",
    "    light_direction_virtual = light_df.loc[light_df[\"filename\"].str.contains(meta_filename+\"_cropped_virtual\", na=False), \"results\"].values[0]\n",
    "    light_direction_whole = light_df.loc[light_df[\"filename\"] == meta_filename+\"_raw\", \"results\"].values[0]\n",
    "\n",
    "    csv_mask = df[\"filename\"] == meta_filename\n",
    "    if csv_mask.any():\n",
    "        df.loc[csv_mask, \"light_direction_real_list\"] = light_direction_real_list\n",
    "        df.loc[csv_mask, \"light_direction_virtual\"] = light_direction_virtual\n",
    "        df.loc[csv_mask, \"light_direction_whole\"] = light_direction_whole\n",
    "        df.to_csv(csv_file, index=False)  # Save back to CSV\n",
    "        print(f\"Updated light direction for {meta_filename} -> {light_direction_real_list}, {light_direction_whole}, {light_direction_virtual}\")\n",
    "    else:\n",
    "        print(f\"Filename {meta_filename} not found in CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the shadow value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of Excel files to combine\n",
    "xlsx_files = ['ARQA_confidence_score.xlsx', 'ARpatches_confidence_score.xlsx', 'cropped_real_confidence_score.xlsx']\n",
    "\n",
    "# Read and combine all Excel files\n",
    "combined_df = pd.concat([pd.read_excel(file) for file in xlsx_files], ignore_index=True)\n",
    "\n",
    "# Save to CSV\n",
    "combined_df.to_csv('shadow_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shadow_csv_file = \"shadow_results.csv\"\n",
    "shadow_df = pd.read_csv(shadow_csv_file, dtype={\"filename\": str})\n",
    "\n",
    "for meta_filename in meta_filenames:\n",
    "    shadow_real_list = shadow_df.loc[shadow_df[\"filename\"].str.contains(meta_filename+\"_cropped\", na=False) \n",
    "                                             & ~shadow_df[\"filename\"].str.contains(\"virtual\", na=False) \n",
    "                                             & ~shadow_df[\"filename\"].str.contains(\"background\", na=False), \"results\"].tolist()\n",
    "    shadow_virtual = shadow_df.loc[shadow_df[\"filename\"].str.contains(meta_filename+\"_cropped_virtual\", na=False), \"results\"].values[0]\n",
    "    shadow_whole = shadow_df.loc[shadow_df[\"filename\"] == meta_filename+\"_raw\", \"results\"].values[0]\n",
    "\n",
    "    csv_mask = df[\"filename\"] == meta_filename\n",
    "    if csv_mask.any():\n",
    "        df.loc[csv_mask, \"shadow_real_list\"] = light_direction_real_list\n",
    "        df.loc[csv_mask, \"shadow_virtual\"] = shadow_virtual\n",
    "        df.loc[csv_mask, \"shadow_whole\"] = shadow_whole\n",
    "        df.to_csv(csv_file, index=False)  # Save back to CSV\n",
    "        print(f\"Updated shadow for {meta_filename} -> {shadow_real_list}, {shadow_whole}, {shadow_virtual}\")\n",
    "    else:\n",
    "        print(f\"Filename {meta_filename} not found in CSV.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the rule-based score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to initialize the CSV file with 10 filenames\n",
    "def initialize_rule_csv(csv_file, filenames):\n",
    "    csv_columns = [\n",
    "        \"filename\", \n",
    "        \"visual_coherence\", \"size\", \"clipping\", \"floating\", \"obstruction\", \n",
    "        \"brightness\", \"light_direction\", \"shadow\"\n",
    "    ]\n",
    "    # If the CSV doesn't exist or is empty, create it with default values\n",
    "    if not os.path.exists(csv_file) or os.stat(csv_file).st_size == 0:\n",
    "        df = pd.DataFrame(columns=csv_columns)  # Create empty DataFrame with correct columns\n",
    "        \n",
    "        # Add 10 filenames with \"N/A\" for all other columns\n",
    "        df[\"filename\"] = filenames\n",
    "        for col in csv_columns[1:]:  # Set all other columns to \"N/A\"\n",
    "            df[col] = \"N/A\"\n",
    "\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        print(f\"Initialized CSV with 10 filenames: {csv_file}\")\n",
    "    else:\n",
    "        print(f\"CSV already exists and is not empty: {csv_file}\")\n",
    "\n",
    "rule_csv_file = \"Testing_rule_based_scores.csv\"\n",
    "print(meta_filenames)\n",
    "initialize_rule_csv(rule_csv_file, list(meta_filenames))\n",
    "\n",
    "rule_df = pd.read_csv(rule_csv_file, dtype={\"filename\": str})\n",
    "\n",
    "size_typical_range_dic = {\n",
    "        \"scissors\": [15, 25],\n",
    "        \"knife\": [15, 30],\n",
    "        \"stop_sign\": [76, 90],\n",
    "        \"candle\": [8, 30],\n",
    "        \"baby\": [45, 60],\n",
    "        \"person\": [150, 180],\n",
    "        \"shoes\": [23, 30],\n",
    "        \"basketball\": [24, 25],\n",
    "        \"football\": [28, 30],\n",
    "        \"chair\": [40, 100],  # Seat height ~40 cm, full height ~100 cm\n",
    "        \"table\": [70, 150],  # Small ~70 cm, large dining ~150 cm\n",
    "        \"apple\": [8, 10],\n",
    "        \"toy\": [5, 100],  # Varies widely\n",
    "        \"box\": [10, 100],  # Small ~10 cm, large ~100 cm\n",
    "        \"cupnoodle\": [10, 12],\n",
    "        \"pillow\": [30, 80],  # Small ~30 cm, large body pillow ~80 cm\n",
    "        \"handglove\": [20, 25],\n",
    "        \"balloon\": [20, 50],  # Deflated ~20 cm, large inflated ~50 cm\n",
    "        \"basket\": [20, 60],  # Small ~20 cm, large ~60 cm\n",
    "        \"can\": [12, 15],\n",
    "        \"car\": [350, 500],  # Small car ~350 cm, large car ~500 cm\n",
    "        \"painting\": [30, 150],  # Small ~30 cm, large wall painting ~150 cm\n",
    "        \"skull\": [20, 25],\n",
    "        \"brain\": [14, 17],\n",
    "        \"eye\": [2, 2.5],\n",
    "        \"heart\": [10, 15],\n",
    "        \"leg\": [2.5, 40],  # Small ~10 cm, femur ~50 cm\n",
    "        \"liver\": [10, 23],  # Varies by type\n",
    "        \"remote_controller\": [15, 25],\n",
    "        \"laptop\": [30, 45],  # Thin laptops ~30 cm, large ~45 cm\n",
    "        \"keyboard\": [43, 50],  # Standard ~43 cm, extended ~50 cm\n",
    "        \"desktop\": [38, 60],  # Varies by case size\n",
    "        \"bottle\": [20, 35],  # Small ~20 cm, large ~35 cm\n",
    "        \"pot\": [15, 40],  # Small saucepan ~15 cm, large stockpot ~40 cm\n",
    "        \"bowl\": [10, 30],  # Small ~10 cm, large ~30 cm\n",
    "        \"tissue_box\": [20, 30],\n",
    "        \"cat\": [30, 90],  # Small kittens ~30 cm, large breeds ~90 cm (nose to tail)\n",
    "        \"door\": [200, 210],\n",
    "        \"desk\": [70, 180],  # Small ~70 cm, large work desk ~180 cm\n",
    "        \"cup\": [8, 15],\n",
    "        \"book\": [20, 40],  # Small ~20 cm, large coffee table book ~40 cm\n",
    "        \"lamp\": [38, 180],  # Small table lamps ~38 cm, large floor lamps ~180 cm\n",
    "        \"backpack\": [10, 70]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "def get_size_score(meta_filename, size):\n",
    "    size_cm = size * 100.0\n",
    "    print(size_cm)\n",
    "    object_class = meta_filename.split(\"_\")[1].lower()\n",
    "    object_class = re.sub(r'\\d+', '', object_class)\n",
    "    object_class = object_class.replace(\"wired\", \"\")\n",
    "    object_class = object_class.replace(\"lobester\", \"\")\n",
    "    object_class = object_class.replace(\"pepsi\", \"can\")\n",
    "    typical_min = size_typical_range_dic[object_class][0]\n",
    "    typical_max = size_typical_range_dic[object_class][1]\n",
    "\n",
    "    score = -1\n",
    "    tmp = -1\n",
    "    if size_cm > typical_max:\n",
    "        tmp = (size_cm - typical_max)/typical_max\n",
    "    elif size_cm < typical_min:\n",
    "        tmp = (typical_min - size_cm)/typical_min\n",
    "    else:\n",
    "        score = 5\n",
    "\n",
    "    if score == -1:\n",
    "        if tmp <= 0.2:\n",
    "            score = 5\n",
    "        elif tmp > 0.2 and tmp <= 0.4:\n",
    "            score = 4\n",
    "        elif tmp > 0.4 and tmp <= 1.5:\n",
    "            score = 3\n",
    "        elif tmp > 1.5 and tmp <= 2.0:\n",
    "            score = 2\n",
    "        else:\n",
    "            score = 1\n",
    "    \n",
    "\n",
    "    return score\n",
    "\n",
    "def get_clipping_score(clipping_area_cnt):\n",
    "    score = -1\n",
    "    if clipping_area_cnt == 1:\n",
    "        score = 5\n",
    "    elif clipping_area_cnt > 2:\n",
    "        score = 1\n",
    "    elif clipping_area_cnt == 2:\n",
    "        score = 2  \n",
    "    else:\n",
    "        score = random.randint(3, 4)\n",
    "    return score\n",
    "\n",
    "def get_floating_score(depth_diff, contact_ratio):\n",
    "    score = -1\n",
    "    if depth_diff <= 0.01:\n",
    "        score = 5\n",
    "    elif depth_diff > 0.01 and depth_diff <= 0.05:\n",
    "        score = 4\n",
    "    elif depth_diff > 0.05 and depth_diff <= 0.2:\n",
    "        score = 3\n",
    "    elif depth_diff > 0.2 and depth_diff <= 0.3:\n",
    "        score = 2\n",
    "    else:\n",
    "        score = 1\n",
    "    \n",
    "    \n",
    "    if contact_ratio >= 0.8:\n",
    "        score = 5\n",
    "    elif contact_ratio >= 0.4 and contact_ratio < 0.6:\n",
    "        score = min(score+1, 5)\n",
    "    elif contact_ratio >= 0.2 and contact_ratio < 0.4:\n",
    "        score = score\n",
    "    else:\n",
    "        score = 1\n",
    "    \n",
    "    if depth_diff==-1 and contact_ratio==-1:\n",
    "        score = 3\n",
    "    return score\n",
    "\n",
    "def get_obstruction_score(meta_filename, percetage, strength, coverage):\n",
    "    obstruction_csv_file = \"shadow_light_obstruct_estimated_values/obstruction_estimated_values.csv\"\n",
    "    obstruction_df = pd.read_csv(obstruction_csv_file, dtype={\"filename\": str})\n",
    "\n",
    "    score = obstruction_df.loc[obstruction_df[\"filename\"] == meta_filename, \"pred_score\"].values[0]\n",
    "\n",
    "    return score\n",
    "\n",
    "def get_brightness_score(meta_filename, min, max, virtual):\n",
    "    score = -1\n",
    "    tmp = -1\n",
    "    if max == min:\n",
    "        max = np.max([max, 100])\n",
    "        min = np.min([min, 100])\n",
    "    if virtual > max:\n",
    "        tmp = (virtual - max)/(max-min)\n",
    "    elif virtual < min:\n",
    "        tmp = (min - virtual)/(max-min)\n",
    "    else:\n",
    "        score = 5\n",
    "\n",
    "    if score == -1:\n",
    "        if tmp <= 0.5:\n",
    "            score = 4\n",
    "        elif tmp > 0.5 and tmp <= 0.7:\n",
    "            score = 3\n",
    "        elif tmp > 0.7 and tmp <= 1.0:\n",
    "            score = 2\n",
    "        else:\n",
    "            score = 1\n",
    "    return score\n",
    "\n",
    "def get_light_direction_score(real_list, whole, virtual):\n",
    "    score = -1\n",
    "    real_list = ast.literal_eval(real_list)\n",
    "    \n",
    "    value_whole = whole == virtual\n",
    "    if len(real_list) == 0:\n",
    "        value_single = 1\n",
    "    else:\n",
    "        value_single = real_list.count(virtual)/len(real_list)\n",
    "    ratio = 0.5*value_single + 0.5*value_whole\n",
    "\n",
    "    if ratio<0.2:\n",
    "        score = 1\n",
    "    elif ratio>=0.2 and ratio<0.25:\n",
    "        score = 2\n",
    "    elif ratio>=0.25 and ratio<0.7:\n",
    "        score = 3\n",
    "    elif ratio>=0.7 and ratio<0.75:\n",
    "        score = 4\n",
    "    else:\n",
    "        score = 5\n",
    "    return score\n",
    "\n",
    "def get_shadow_score(real_list, whole, virtual):\n",
    "    score = -1\n",
    "    real_list = ast.literal_eval(real_list)\n",
    "    print(\"shadow real list\",real_list)\n",
    "    if len(real_list)==0:\n",
    "        return 4\n",
    "    \n",
    "    real_max = np.max(real_list)\n",
    "    real_min = np.min(real_list)\n",
    "    if virtual >= real_max:\n",
    "        score = 5\n",
    "    elif virtual < real_min:\n",
    "        score = 1\n",
    "    else:\n",
    "        virtual_norm = virtual\n",
    "        if real_min != real_max:\n",
    "            virtual_norm = (virtual-real_min)/(real_max - real_min)\n",
    "        if virtual_norm < 0.1:\n",
    "            score = 1\n",
    "        elif virtual_norm >= 0.1 and virtual_norm < 0.6: \n",
    "            score = 2\n",
    "        elif virtual_norm >= 0.6 and virtual_norm < 0.7: \n",
    "            score = 3\n",
    "        elif virtual_norm >= 0.7 and virtual_norm < 1.0: \n",
    "            score = 4\n",
    "        else: \n",
    "            score = 5\n",
    "    return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
